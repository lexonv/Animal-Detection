# -*- coding: utf-8 -*-
"""MSI_projekt_g1b_gr1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jhi11ljtZTTMuHLHazIkomRUbYh1Ul6B

Tytuł projektu: Detekcja Zwierząt

Członkowie zespołu: Artur Mierzlikin Piotr Olbryś

Import potrzebnych bibliotek
"""

import json
import zipfile
dictionary = {"username":"gr1b1ampo","key":"9dbe4067cac25d370a49f3416b806e05"}
with open("kaggle.json","w") as outfile:
  json.dump(dictionary,outfile)
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets list

!kaggle datasets download -d antoreepjana/animals-detection-images-dataset

with zipfile.ZipFile("animals-detection-images-dataset.zip",'r') as zip_ref:
  zip_ref.extractall("dataset")

import torch
import torchvision
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
import albumentations
import numpy as np
import matplotlib.pyplot as plt
import os
import cv2
import glob
import pandas as pd
import re

dataset_path = "dataset"

train_dir = os.path.join(dataset_path,"train")
test_dir = os.path.join(dataset_path,"test")
train_subdirs = glob.glob(train_dir+"/*")
test_subdirs = glob.glob(test_dir+"/*")
train_classes = [os.path.basename(cl) for cl in train_subdirs]
nazwy_klas = train_classes.sort()
print(train_classes)
test_classes = [os.path.basename(cl) for cl in test_subdirs]
class_count_train = len(train_classes)
class_count_test = len(test_classes)
print("Ilość klas w danych treningowych: %d, w danych testowych: %d"%(class_count_train,class_count_test))

"""Statystyki co do ilości obrazów

"""

img_train = {os.path.basename(cl):[len(glob.glob(os.path.join(cl, "*.jpg")))] for cl in train_subdirs}
img_test = {os.path.basename(cl):[len(glob.glob(os.path.join(cl, "*.jpg")))] for cl in test_subdirs}
img_train_df = pd.DataFrame(img_train, index=["train"]).transpose()
img_test_df = pd.DataFrame(img_test, index=["test"]).transpose()
img_all_df = pd.concat([img_train_df,img_test_df],axis=1)
print(img_train_df)
img_all_df = img_all_df.sort_values(by = ["train","test"], ascending = False)
img_all_df.plot(kind="bar", legend = True,figsize = (30,8), title = "Ilość zdjęć w każdej klasie")
print(img_all_df)

#zgrupuj dane w zmienne o strukturze (nazwa zwierzęcia, dane)
#zmienna labelki - przechowuje "nazwy" zwierząt w postaci liczb, np. hipopotam - 1.0
#zmienna nazwy_train - przechowuje dane odczytane z datasetu (nazwa w stringu + 4 zmienne zmiennoprzecinkowe)
label_train = []
nazwy_train = []
iter = -1.0

for root, dirs, files in os.walk(train_dir):
  if dirs:
   iter = iter + 1.0
  for file in files:
        if file.endswith('.txt'):
            with open(os.path.join(root, file), 'r') as f:
               for line in f:
                if(root == "dataset/train/Brown bear/Label" or "dataset/test/Harbor seal/Label" or "dataset/train/Polar bear/Label" or "dataset/train/Red panda/Label" or root == "dataset/train/Harbor Seal/Label" or root == "dataset/train/Sea lion/Label" or root == "dataset/train/Sea turtle/Label"):
                  line = line.strip()
                  columns = re.split('\s+', line, maxsplit=5)
                  label_train.append(columns)
                elif(root == "dataset/train/Moths and butterflies/Label"):
                  line = line.strip()
                  columns = re.split('\s+', line, maxsplit=6)
                  label_train.append(columns)
                else:
                  line = line.strip()
                  columns = re.split('\s+', line, maxsplit=4)
                  label_train.append(columns)
                nazwy_train.append([iter])



label_test = []
nazwy_test = []
iter = -1.0
for root, dirs, files in os.walk(test_dir):
  if dirs:
    iter = iter + 1.0
  for file in files:
        if file.endswith('.txt'):
            with open(os.path.join(root, file), 'r') as f:
                for line in f:
                  if(root == "dataset/test/Brown bear/Label" or "dataset/test/Harbor seal/Label" or "dataset/test/Polar bear/Label" or "dataset/test/Red panda/Label" or root == "dataset/test/Harbor Seal/Label" or root == "dataset/test/Sea lion/Label" or root == "dataset/test/Sea turtle/Label"):
                    line = line.strip()
                    columns = re.split('\s+', line, maxsplit=5)
                    label_test.append(columns)
                  elif(root == "dataset/test/Moths and butterflies/Label"):
                    line = line.strip()
                    columns = re.split('\s+', line, maxsplit=6)
                    label_test.append(columns)
                  else:
                    line = line.strip()
                    columns = re.split('\s+', line, maxsplit=4)
                    label_test.append(columns)
                  nazwy_test.append([iter])



#test poprawności kodu, sprawdza czy jest tyle samo elementów w wektorze label i nazwy dla każdego zwierzęcia
print(label_train)
zliczaj1 = 0.0
for k in range(len(label_test)):
  if label_test[k][0] == "Turtle":
    zliczaj1 = zliczaj1 + 1.0
print(zliczaj1)

zliczaj2 = 0.0
for k in range(len(nazwy_test)):
  if nazwy_test[k][0] == 2.0:
    zliczaj2 = zliczaj2 + 1.0
print(zliczaj2)

"""Statystyki
-
"""

imgs_refTRAIN = []
imgs_refTEST = []


# Przeiteruj po datasecie, odczytaj ADRESY zdjęć i zapisz je do listy.
for dirpath, dirnames, filenames in os.walk(train_dir):
    for filename in filenames:
        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            img_path = os.path.join(dirpath, filename)
            imgs_refTRAIN.append(img_path)

for dirpath, dirnames, filenames in os.walk(test_dir):
    for filename in filenames:
        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            img_path = os.path.join(dirpath, filename)
            imgs_refTEST.append(img_path)

# sizes = np.array(sizes)
# resolutions = np.array(resolutions)

"""Załadowanie datasetu:
- zdefiniuj batch_size
- zdefiniuj transformacje (np. normalizacja, augmentacja); pamiętaj, że dane muszą być zapisane w postaci tensorów
- wczytaj dataset z odpowiednimi właściwościami
- stwórz dataloader
- wczytaj bounding-boxy i klasy (target)

Dla większej przejrzystości możesz stworzyć osobną klasę o nazwie Dataset, która będzie tworzyła pary [image, target], gdzie target będzie słownikiem, w którym będą klasy, bounding-boxy czy inne informacje.
"""

#UWAGA JEST TO TESTOWY KOD, NIE JEST ON WYKORZYSTYWANY
#stworz wektor z samymi danymi
#tworzy dane do wczytania "paczkami" o długości batch_size
#UWAGA: USUWA NAZWY ZWIERZĄT, ZAWIERA TYLKO DANE O BOUNDSACH W ZMIENNEJ trainloader
#zmienne targety - przechowują nazwy zwierząt w postaci liczb (osobne wektory dla danych i nazw)

trainset = label_train
trainloader = trainset
wektor_train = []
for i in range(len(trainloader)):
  w1 = trainloader[i][-1]
  w2 = trainloader[i][-2]
  w3 = trainloader[i][-3]
  w4 = trainloader[i][-4]
  wektor_train.append([w4,w3,w2,w1])
trainloader = wektor_train

#konwersja z str -> float
for i in range(len(wektor_train)):
  for j in range(len(wektor_train[0])):
    wektor_train[i][j] = float(wektor_train[i][j])

dane_train = nazwy_train[0:batch_size]

#umieść nazwy klasy (1, 2, 3 itd.) do targetu test
for i in range(len(dane_train)):
  trainloader[i].insert(0, dane_train[i][0])

#konwersja z list do array
target_train = np.array(map(float, trainloader))
print(target_train)

#---------------------------------
testset = label_test
testloader = testset
wektor_test = []
for i in range(len(testloader)):
  w1 = testloader[i][-1]
  w2 = testloader[i][-2]
  w3 = testloader[i][-3]
  w4 = testloader[i][-4]
  wektor_test.append([w4,w3,w2,w1])

testloader = wektor_test

#konwersja z str -> float
for i in range(len(wektor_test)):
  for j in range(len(wektor_test[0])):
    wektor_test[i][j] = float(wektor_test[i][j])

dane_test = nazwy_test[0:batch_size]

#umieść nazwy klasy (1, 2, 3 itd.) do targetu test
for i in range(len(dane_test)):
  testloader[i].insert(0, dane_test[i][0])

#konwersja z list do array
target_test = np.array(map(float, testloader))

from torchvision.transforms import v2 as T
class Compose:
    def __init__(self, transforms):
        self.transforms = transforms

    def __call__(self, image, target):
        for t in self.transforms:
            image, target = t(image, target)
        return image, target

class ToTensor:
    def __call__(self, image, target):
        image = T.functional.to_tensor(image)
        return image, target

class RandomHorizontalFlip:
    def __init__(self, p=0.5):
        self.p = p

    def __call__(self, image, target):
        if torch.rand(1) < self.p:
            image = T.functional.hflip(image)
            bbox = target["boxes"]
            width = image.shape[2]
            bbox[:, [0, 2]] = width - bbox[:, [2, 0]]
            target["boxes"] = bbox
        return image, target

def get_transform(train):
    transforms = [ToTensor()]
    if train:
        transforms.append(RandomHorizontalFlip(0.5))
    return Compose(transforms)

#Definicje funkcji potrzebnych do stworzenia Datasetu (już customowe)
import os
import torch
from torchvision.io import read_image
from torchvision import tv_tensors
from torchvision.transforms.v2 import functional as F
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as T
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from PIL import Image

#-------------------------------------------------------------------------------\
dataset_path = "dataset"
train_dir = os.path.join(dataset_path,"train")
train_subdirs = glob.glob(train_dir+"/*")
train_classes = [os.path.basename(cl) for cl in train_subdirs]
train_classes.sort()
print(train_classes)
#-------------------------------------------------------------------------------
class PennFudanDataset(Dataset):
    def __init__(self, root, selected_folders = None ,transforms=None):
        ilosc_zdjec = 10
        self.root = root
        self.transforms = transforms
        self.imgs = []
        self.annos = []
        self.classes = ["__background__"]
        self.lista_root = []
        imgs_new = []
        annos_new = []
        classes_new = []

        if selected_folders is None:
            selected_folders = train_classes

        for class_name in train_classes:
            class_img_folder = os.path.join(root, class_name)
            class_anno_folder = os.path.join(root, class_name, "Label")

            if os.path.isdir(class_img_folder) and os.path.isdir(class_anno_folder):
                class_imgs = [os.path.join(class_img_folder, f) for f in os.listdir(class_img_folder) if os.path.isfile(os.path.join(class_img_folder, f))]
                class_annos = [os.path.join(class_anno_folder, f) for f in os.listdir(class_anno_folder) if os.path.isfile(os.path.join(class_anno_folder, f))]
                # print(len(class_imgs))
                # print(len(class_annos))
                class_imgs = sorted(class_imgs)
                class_annos = sorted(class_annos)
                for k in range(10):
                  if k < len(class_annos):
                    self.imgs.append(class_imgs[k])
                    self.annos.append(class_annos[k])
                    # classes_new.append(self.classes)
                    self.lista_root.append(class_anno_folder)
                self.classes.append(class_name)
                # print(self.imgs)
                # print(len(self.annos))
                # for i in range(ilosc_zdjec):

        # self.classes = classes_new
        print(self.classes)
        self.imgs = sorted(self.imgs)
        self.annos = sorted(self.annos)
        self.lista_root = sorted(self.lista_root)
        print(len(self.lista_root))
        print(len(self.imgs))
        print(len(self.annos))
    def __getitem__(self, idx):
        # load images
        img_path = self.imgs[idx]
        anno_path = self.annos[idx]
        img = Image.open(img_path).convert("RGB")
        lroot = self.lista_root[idx]
        # print(lroot)

        # get bounding box coordinates for each mask
        boxes = []
        labels = []
        if (lroot == "dataset/train/Brown bear/Label" or lroot == "dataset/train/Harbor seal/Label" or lroot == "dataset/train/Polar bear/Label" or lroot == "dataset/train/Red panda/Label" or lroot == "dataset/train/Sea lion/Label"
            or lroot == "dataset/train/Sea turtle/Label" or lroot == "dataset/test/Brown bear/Label" or lroot == "dataset/test/Harbor seal/Label" or lroot == "dataset/test/Sea lion/Label" or lroot == "dataset/test/Sea turtle/Label"
            or lroot == "dataset/test/Red panda/Label" or lroot == "dataset/test/Polar bear/Label"):
          with open(anno_path) as f:
            linecount = 0
            for line in f:
                linecount += 1
                parts = line.strip().split()
                # print(1)
                if linecount == 1:
                  class_name = parts[0] + ' ' + parts[1]
                  xmin = float(parts[-4])
                  ymin = float(parts[-3])
                  xmax = float(parts[-2])
                  ymax = float(parts[-1])
                  boxes.append([xmin, ymin, xmax, ymax])
                  labels.append(self.classes.index(class_name))
        elif (lroot == "dataset/train/Moths and butterflies/Label" or lroot == "dataset/test/Moths and butterflies/Label"):
          with open(anno_path) as f:
              linecount = 0
              for line in f:
                linecount += 1
                parts = line.strip().split()
                # print(2)
                if linecount == 1:
                  class_name = parts[0] + ' '  + parts[1] + ' '  + parts[2]
                  xmin = float(parts[-4])
                  ymin = float(parts[-3])
                  xmax = float(parts[-2])
                  ymax = float(parts[-1])
                  boxes.append([xmin, ymin, xmax, ymax])
                  labels.append(self.classes.index(class_name))
        elif not (lroot == "dataset/train/Brown bear/Label" or lroot == "dataset/train/Harbor seal/Label" or lroot == "dataset/train/Polar bear/Label" or lroot == "dataset/train/Red panda/Label" or lroot == "dataset/train/Sea lion/Label"
            or lroot == "dataset/train/Sea turtle/Label" or lroot == "dataset/test/Brown bear/Label" or lroot == "dataset/test/Harbor seal/Label" or lroot == "dataset/test/Sea lion/Label" or lroot == "dataset/test/Sea turtle/Label"
            or lroot == "dataset/test/Red panda/Label" or lroot == "dataset/train/Moths and butterflies/Label" or lroot == "dataset/test/Moths and butterflies/Label" or lroot == "dataset/test/Polar bear/Label"):
          with open(anno_path) as f:
            linecount = 0
            for line in f:
                linecount += 1
                # print(3)
                if linecount == 1:
                  parts = line.strip().split()
                  # print(parts)
                  class_name = parts[0]
                  xmin = float(parts[-4])
                  ymin = float(parts[-3])
                  xmax = float(parts[-2])
                  ymax = float(parts[-1])
                  boxes.append([xmin, ymin, xmax, ymax])
                  labels.append(self.classes.index(class_name))


        # label danego zdjęcia
        boxes = torch.as_tensor(boxes, dtype=torch.float32)
        labels = torch.as_tensor(labels, dtype=torch.int64)

        # print(boxes)
        image_id = torch.tensor([idx])
        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])
        iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)
        target = {
            "boxes": boxes,
            "labels": labels,
            "image_id": image_id,
            "area": area,
            "iscrowd": iscrowd
        }

        if self.transforms is not None:
            img, target = self.transforms(img, target)

        return img, target

    def __len__(self):
      return len(self.imgs)


test = PennFudanDataset('dataset/train', get_transform(train=True))
#-------------------------------------------------------------------------------

"""# Zdefiniuj swoją sieć:
- stwórz klasę, w której zdefiniujesz własną sieć
lub skorzystasz z już przeuczonej
- stwórz funkcję inicjującą warstwy sieci
- pamiętaj o stworzeniu funkcji forward,
  która odpowiada za przejście danych uczących przez sieć
- stwórz obiekt 'net' tej klasy
"""

import torchvision
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor

#Przetrenowana sieć
model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights="DEFAULT")
num_classes = 80
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

# def get_model_instance_segmentation(num_classes):
#     # load an instance segmentation model pre-trained on COCO
#     model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights="DEFAULT")

#     # get number of input features for the classifier
#     in_features = model.roi_heads.box_predictor.cls_score.in_features
#     # replace the pre-trained head with a new one
#     model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

#     # now get the number of input features for the mask classifier
#     in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels
#     hidden_layer = 256
#     # and replace the mask predictor with a new one
#     model.roi_heads.mask_predictor = MaskRCNNPredictor(
#         in_features_mask,
#         hidden_layer,
#         num_classes
#     )

#     return model

os.system("wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/engine.py")
os.system("wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py")
os.system("wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py")
os.system("wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py")
os.system("wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/transforms.py")

# class Net(nn.Module):
#     def __init__(self):
#       super().__init__()

#     def forward(self, x):
#       pass
# net = None

#Forward test

import utils

#Przetrenowana sieć
model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights="DEFAULT")
num_classes = len(train_classes) + 1
in_features = model.roi_heads.box_predictor.cls_score.in_features
model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

dataset = PennFudanDataset('dataset/train', get_transform(train=True))
data_loader = torch.utils.data.DataLoader(
    dataset,
    batch_size=2,
    shuffle=True,
    num_workers=2,
    collate_fn=utils.collate_fn
)

# For Training
images, targets = next(iter(data_loader))
images = list(image for image in images)
targets = [{k: v for k, v in t.items()} for t in targets]
output = model(images, targets)  # Returns losses and detections
print(output)

#-------------------------------------------------------------------------------
#Trening?

from engine import train_one_epoch, evaluate
import utils

# train on the GPU or on the CPU, if a GPU is not available
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

# liczba klas
num_classes = len(train_classes) + 1
# use our dataset and defined transformations
dataset = PennFudanDataset('dataset/train', selected_folders=train_classes, transforms=get_transform(train=True))
dataset_test = PennFudanDataset('dataset/test', selected_folders=train_classes, transforms=get_transform(train=True))

def collate_fn(batch):
    return tuple(zip(*batch))

def create_data_loader(dataset, batch_size=2, shuffle=True, num_workers=4):
    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, collate_fn=collate_fn)

def get_model(num_classes):
    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    return model


# define training and validation data loaders
data_loader = create_data_loader(dataset)
data_loader_test = create_data_loader(dataset_test, batch_size=2, shuffle=False, num_workers=4)
# get the model using our helper function
model = get_model(num_classes)

#Przetrenowana sieć

# move model to the right device
model.to(device)

# construct an optimizer
params = [p for p in model.parameters() if p.requires_grad]
optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)
# and a learning rate scheduler
# lr_scheduler = torch.optim.lr_scheduler.StepLR(
#     optimizer,
#     step_size=3,
#     gamma=0.1
# )

# let's train it just for 2 epochs
num_epochs = 2
num_batches = len(data_loader)
for epoch in range(num_epochs):
    model.train()
    for i, (images, targets) in enumerate(data_loader):
        images = list(image.to(device) for image in images)
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

        loss_dict = model(images, targets)
        losses = sum(loss for loss in loss_dict.values())

        optimizer.zero_grad()
        losses.backward()
        optimizer.step()

        print(f"Epoch [{epoch}/{num_epochs}], Iteration [{i}/{num_batches}], Loss: {losses.item()}")
    # loss = train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)
    # lr_scheduler.step()
evaluate(model, data_loader_test, device=device)





# # def evaluate
# def evaluate(model, data_loader, device):
#     model.eval()
#     for images, targets in data_loader:
#         images = list(image.to(device) for image in images)
#         with torch.no_grad():
#             outputs = model(images)

#         for i, output in enumerate(outputs):
#             img = images[i].permute(1, 2, 0).cpu().numpy()
#             boxes = output['boxes'].cpu().numpy()
#             labels = output['labels'].cpu().numpy()
#             scores = output['scores'].cpu().numpy()

#             # Filtruj wyniki według progu pewności
#             threshold = 0.5
#             keep = scores >= threshold
#             boxes = boxes[keep]
#             labels = labels[keep]
#             scores = scores[keep]

#             label_names = [dataset_test.classes[label] for label in labels]

#             plot_image(img, boxes, label_names)



# evaluate(model,data_loader_test,device)

print("\n Końcowa wartość funkcji loss = " + str(losses.item()))

"""Zdefiniuj funkcję celu oraz optymalizator:"""

torch.save(model.state_dict(), 'fasterrcnn_model.pth')

model.train()
for i, (images, targets) in enumerate(data_loader):
       images = list(image.to(device) for image in images)
       print(targets.items())
       targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

from engine import train_one_epoch, evaluate
evaluate(model, data_loader_test, device=device)

"""Zdefiniuj pętlę treningową:
- zdefiniuj liczbę epok - liczbę iteracji przejścia przez sieć
- zdefiniuj dane wejściowe w postaci [inputs, target]
- wyzeruj gradient
- podaj dane wejściowe na sieć
- oblicz loss
- dodaj optymalizację
- wyświetl statystyki dla tej epoki

"""

def plot_image(img, boxes, labels):
    fig, ax = plt.subplots(1, 1, figsize=(12, 9))
    ax.imshow(img)
    for box, label in zip(boxes, labels):
        xmin, ymin, xmax, ymax = box
        rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color='red', linewidth=2)
        ax.add_patch(rect)
        ax.text(xmin, ymin, label, bbox={'facecolor': 'white', 'alpha': 0.5})
    plt.show()

def evaluate(model, data_loader, device):
    model.eval()
    for images, targets in data_loader:
        images = list(image.to(device) for image in images)

        with torch.no_grad():
            outputs = model(images)
            print(outputs)

        for i, output in enumerate(outputs):
            img = images[i].permute(1, 2, 0).cpu().numpy()
            boxes = output['boxes'].cpu().numpy()
            labels = output['labels'].cpu().numpy()
            scores = output['scores'].cpu().numpy()

            # Filtruj wyniki według progu pewności
            threshold = 0.5
            keep = scores >= threshold
            boxes = boxes[keep]

            labels = labels[keep]
            scores = scores[keep]

            # label_names = [dataset_test.classes[label] for label in labels]

            # plot_image(img, boxes, label_names)




evaluate(model,data_loader_test,device)

"""Zapisz wagi modelu"""

model.eval()

"""Wyświetl przykładowe obrazy:
- wczytaj wagi modelu
- przetestuj sieć na obrazach
- wyświetl obrazy
- wyświetl prawdziwe oznaczenia
- wyświetl predykcje wygenerowane przez sieć
"""









"""Oblicz metryki:
- oblicz dokładność dla całego zbioru
- oblicz dokładność dla każdej z klas
- oblicz pozostałe metryki istotne dla ewaluacji detekcji
"""





